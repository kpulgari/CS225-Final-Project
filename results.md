Our leading question was to create a search tool that finds the distance between two Wikipedia nodes, and an algorithm that ranks the pages based on importance. We answered these questions by writing three algorithms that accomplish these goals: we implemented a BFS traversal to find the shortest path between two nodes, an IDDFS algorithm that also finds the shortest path between two nodes, and a PageRank algorithm that finds the “significance” of each node and returns the node with the highest importance. However, we were unable to implement a function that directly compares the performance (runtime and space complexity) between the BFS traversal and IDDFS algorithm. As a group, we had issues making the files on some of our computers, so we were limited in some ways productively. To resolve this, those of us that were having these issues had to run our code on other members’ machines. This resulted in a somewhat limited development framework, but we were mostly able to get around this with good collaboration and communication.

For our graph representation of our data, we made a Node struct with the following fields: title, edges, and significance. The title is a string that represents the name of the Wikipedia page. Edges are vectors of integers that represent the ids of each of the pages that the page contains links to. Significance is a double that is populated when we run our PageRank function. It can be thought of as a measure of how important the page is, with pages that have more and higher-quality links having a higher significance value. We then have a map, with integers as keys and Node pointers as values, that represents our graph. The integer keys can be thought of as the ids of the page that the corresponding Node value represents.

Our “BFSpath” function takes in two integers, start and end, which correspond to the ids of two nodes in our dataset. It then performs the BFS algorithm to find the shortest path between the nodes. It keeps track of which nodes are pointing to each other by populating a map, from integer to integer, during the execution of the BFS algorithm. The integers in the map signify nodes’ ids, with the key representing the node being pointed to and the value representing the node the edge is originating from. Once the end node is found, we loop back through this map until we get to the start node, and populate a vector that we return, containing the ids of all the nodes in the shortest path from start to end. We test this function with both the full dataset and a shorter modified version of it. We performed the algorithm by hand on our dataset and ensured that the function returned the same order vector as we got in our test cases. We also tested various edge cases, like when start and end nodes are the same value, to make sure the function performs as expected (returns empty vector). The running time for this function is optimal - O(N + E) - where n is the number of nodes in the graph, and e is the number of edges. Our “IDDFS” function takes in three integers - start, end, and max_depth - and finds the shortest distance between the starting and ending nodes by using an iterative deepening depth-first search. It returns the value of this distance as an integer. The start and end values represent the ids of the nodes we are looking for a path between and the max_depth value is the maximum distance from the start node we check. In the function, for each distance from up through max depth, we call a helper function - DLS - that checks if the end node is within that distance of the starting node. If it is, we return that distance. If we go all the way through max_depth and still don’t find the end node, we return -1. We test this function both by performing the algorithm by hand on our dataset and verifying that the function gets the same result. We also made sure that the function returns one less than the size of the BFSpath vector when called on the same two nodes and that their distance is less than or equal to max_depth. The running time for this function is also O(N + E) - where n is the number of nodes in the graph and e is the number of edges - because it iterates over each node in a given number of levels.

Our function “FindMostSignificantNode” runs through each node in our graph and returns the key (id of node) with the highest significance. We iterate through the entire graph, and each time the current node’s significance is greater than the current maximum significance, we update the maximum significance key and the maximum significance value. The runtime for this function is O(n) - where n is the number of vertices - because it loops through each node in the graph. We made a test case for the sample data only because of the sheer number of nodes in the full dataset (over 4 million), and the fact that significance values are arbitrary. The test case for this function on the sample data passed (node with ID = 20 had the most links and connections, and thus the highest significance), so the function worked properly.

Our function “PopulatePageRank” takes a damping factor (0-100), which determines how likely the function is to skip to a random node in the graph, and an iteration parameter, which indicates how many times the function will iterate through the nodes. Each time a node is visited, the corresponding value in the significance map is incremented by 1, and after going through all the iterations, each node will get assigned a significance value. This value is found by taking the node’s corresponding value in the significance map and then dividing the value by the number of iterations. A low significance value (close to 0), indicates that a node is not significant, whereas higher values indicate higher significance. The running time of this function is O(n), where n is the number of iterations. We wrote test cases comparing the significance of highly importance nodes (many links and edges) with non-important nodes (no links), and the test casses passed. We also checked the correctness of PopulatePageRank by implementing the function within FindMostSignificantNode’s test cases. The node with the most connections and links (ID = 20) was the node returned by FindMostSignificantNode, which means the PopulatePageRank function was correct.
